{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "import imghdr\n",
    "import dlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "import time\n",
    "from shutil import move\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Init for Image Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_loc = r\"\"\n",
    "\n",
    "# Format for below: Abbreviation_full_form(init value)\n",
    "# Min_Confidence(0.9), Min_Size(0.009) (proportional to image size), Min_SharpeningStat(100), Blur_Threshold(100)\n",
    "mc, ms, mss, bt = 0.9, 0.01, 100, 100\n",
    "\n",
    "# Face Crop to dimensions x, y\n",
    "x_crop = 512\n",
    "y_crop = 512\n",
    "\n",
    "# Do not touch this\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "selected_folder = os.path.join(folder_loc, \"SelectedImages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all images to PNG for easier reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_images_to_png(source_folder):\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"The folder {source_folder} does not exist.\")\n",
    "        return\n",
    "\n",
    "    for filename in tqdm(os.listdir(source_folder), desc = \"Processing images to .png\"):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp')):\n",
    "            file_path = os.path.join(source_folder, filename)\n",
    "            with Image.open(file_path) as img:\n",
    "                new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                new_file_path = os.path.join(source_folder, new_filename)\n",
    "                img.save(new_file_path, 'PNG')\n",
    "                os.remove(file_path)\n",
    "\n",
    "convert_images_to_png(folder_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Same Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_bars(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cropped_image = image[y:y+h, x:x+w]\n",
    "        return cropped_image\n",
    "    return image\n",
    "\n",
    "def process_images(folder_path):\n",
    "    duplicate_images_folder = os.path.join(folder_path, \"Duplicate_Images\")\n",
    "    if not os.path.exists(duplicate_images_folder):\n",
    "        os.makedirs(duplicate_images_folder)\n",
    "    \n",
    "    image_hashes = {}\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]\n",
    "    for filename in tqdm(files, desc=\"Processing Images\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        image_no_black_bars = remove_black_bars(image)\n",
    "        \n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image_no_black_bars, cv2.COLOR_BGR2RGB))\n",
    "        hash = str(imagehash.average_hash(pil_image))\n",
    "        \n",
    "        # Check for duplicates\n",
    "        if hash in image_hashes:\n",
    "            print(f\"Duplicate found: {filename} is a duplicate of {image_hashes[hash]}\")\n",
    "            os.rename(file_path, os.path.join(duplicate_images_folder, filename))\n",
    "        else:\n",
    "            image_hashes[hash] = filename\n",
    "    \n",
    "    if len([i for i in os.listdir(duplicate_images_folder)]) == 0:\n",
    "        os.rmdir(duplicate_images_folder)\n",
    "\n",
    "process_images(folder_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks Images for Suitability Check (Face check, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = os.getcwd()\n",
    "\n",
    "modelFile = os.path.join(current_folder, \"opencv_face_detector_uint8.pb\")\n",
    "configFile = os.path.join(current_folder, \"opencv_face_detector.pbtxt\")\n",
    "\n",
    "if os.path.exists(modelFile) != True or os.path.exists(configFile) != True:\n",
    "    print(\"ERROR: KEY FILES FOR RUNNING THIS MODEL NOT FOUND, PLEASE FIND THEM AND INSTALL THEM\")\n",
    "\n",
    "else:\n",
    "    net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    def calculate_image_sharpness(image):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the sharpness of an image using the variance of the Laplacian\n",
    "        \"\"\"\n",
    "        \n",
    "        if image is None or image.size == 0:\n",
    "            return 0\n",
    "        return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "    def is_image_blurry(image, blur_threshold):\n",
    "        \n",
    "        \"\"\"\n",
    "        Check if an image is blurry using the variance of the Laplacian method.\n",
    "        \"\"\"\n",
    "        \n",
    "        variance_of_laplacian = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "        return variance_of_laplacian < blur_threshold\n",
    "\n",
    "    def detect_faces_and_evaluate(image, min_confidence, min_size, min_sharpness, blur_threshold):\n",
    "        \n",
    "        \"\"\"\n",
    "        Detect faces in an image and evaluate based on size, sharpness, and blurriness.\n",
    "        \"\"\"\n",
    "        \n",
    "        if image is None or image.size == 0:\n",
    "            return []\n",
    "        if is_image_blurry(image, blur_threshold):\n",
    "            return []\n",
    "        (h, w) = image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        faces_detected = []\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > min_confidence:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                startX, startY, endX, endY = max(0, startX), max(0, startY), min(w, endX), min(h, endY)\n",
    "                if startX >= endX or startY >= endY:\n",
    "                    continue\n",
    "                face_region = image[startY:endY, startX:endX]\n",
    "                if face_region.size == 0:\n",
    "                    continue\n",
    "                face_size = (endX - startX) * (endY - startY)\n",
    "                face_sharpness = calculate_image_sharpness(face_region)\n",
    "                if face_size > min_size and face_sharpness > min_sharpness:\n",
    "                    faces_detected.append((confidence, face_size, face_sharpness))\n",
    "        return faces_detected\n",
    "\n",
    "    def remove_black_bars(image):\n",
    "        \n",
    "        \"\"\"\n",
    "        Remove black bars from an image.\n",
    "        \"\"\"\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            cropped_image = image[y:y+h, x:x+w]\n",
    "            return cropped_image\n",
    "        return image\n",
    "\n",
    "    def select_best_images(\n",
    "            folder_path:str, \n",
    "            min_confidence:float = 0.9, \n",
    "            min_size:float = 0.009, \n",
    "            min_sharpness:float = 100, \n",
    "            blur_threshold:float = 100\n",
    "            ):\n",
    "        \n",
    "        selected_images_folder = os.path.join(folder_path, \"SelectedImages\")\n",
    "        if not os.path.exists(selected_images_folder):\n",
    "            os.makedirs(selected_images_folder)\n",
    "        \n",
    "        files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]\n",
    "        for filename in tqdm(files, desc=\"Evaluating Images\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(file_path)\n",
    "            if image is None:\n",
    "                continue\n",
    "            \n",
    "            image_no_black_bars = remove_black_bars(image)\n",
    "            \n",
    "            faces_detected = detect_faces_and_evaluate(image_no_black_bars, min_confidence, min_size * image_no_black_bars.size, min_sharpness, blur_threshold)\n",
    "            if len(faces_detected) == 1:\n",
    "                move(file_path, os.path.join(selected_images_folder, filename))\n",
    "\n",
    "    select_best_images(folder_loc, mc, ms, mss, bt)\n",
    "\n",
    "    selected_folder = os.path.join(folder_loc, \"SelectedImages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanved Image Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(selected_folder) != True:\n",
    "    selected_folder = folder_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Background of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background_from_images(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        with open(input_path, 'rb') as input_file:\n",
    "            input_image = input_file.read()\n",
    "\n",
    "            output_image = remove(input_image)\n",
    "\n",
    "            output_image = Image.open(io.BytesIO(output_image))\n",
    "            output_image.save(output_path)\n",
    "\n",
    "remove_background_from_images(selected_folder, os.path.join(selected_folder, \"No_BG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Image to Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_img = []\n",
    "face_failed = []\n",
    "\n",
    "def faceCrop(folder_dir, fName, img, imp=1, x=512, y=512):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    _, ext = os.path.splitext(fName)\n",
    "    \n",
    "    fName = fName.split(\".\")[0]\n",
    "    if ext.lower() not in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']:\n",
    "        print(f\"Unsupported image format: {ext}\")\n",
    "        failed_img.append(fName)\n",
    "        return\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    if len(faces) == 0:\n",
    "        None\n",
    "        # print(\"--> TO BE ADDED\")\n",
    "        face_failed.append(fName)\n",
    "    else:\n",
    "        importance = imp\n",
    "        areas = [face.width() * face.height() for face in faces]\n",
    "        max_area_index = np.argmax(areas)\n",
    "        fx, fy, fw, fh = faces[max_area_index].left(), faces[max_area_index].top(), faces[max_area_index].width(), faces[max_area_index].height()\n",
    "\n",
    "        # Increase the size of the bounding box to include more area around the face\n",
    "        fx = max(0, fx - fw)\n",
    "        fy = max(0, fy - fh)\n",
    "        fw = min(img.shape[1] - fx, fw * 3)\n",
    "        fh = min(img.shape[0] - fy, fh * 3)\n",
    "\n",
    "        # Crop the largest possible square within the bounding box\n",
    "        if fw > fh:\n",
    "            fx += (fw - fh) // 2\n",
    "            fw = fh\n",
    "        else:\n",
    "            fy += (fh - fw) // 2\n",
    "            fh = fw\n",
    "\n",
    "        cropped = img[fy:fy+fh, fx:fx+fw]\n",
    "\n",
    "        # Resize the cropped image to the specified dimensions\n",
    "        cropped = cv2.resize(cropped, (x, y))\n",
    "\n",
    "        cv2.imwrite(os.path.join(folder_dir, fName + '.png'), cropped)\n",
    "\n",
    "def main_call(folder_path, x=512, y=512):\n",
    "    resized_folder_path = os.path.join(folder_path, \"Cropped_Images\")\n",
    "    \n",
    "    if not os.path.exists(resized_folder_path):\n",
    "        print(r\"Made /resized folder\")\n",
    "        os.makedirs(resized_folder_path)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(\"Valid Folder Location\")\n",
    "        files = os.listdir(folder_path)\n",
    "        files_img = [i for i in files if not i.endswith('.txt') and not os.path.isdir(os.path.join(folder_path, i))]\n",
    "        print(\"Number of files: \", len(files_img))\n",
    "        itr = 0\n",
    "        for i in tqdm(files_img, desc=\"Processing Files\"):\n",
    "            itr += 1\n",
    "            file_loc = os.path.join(folder_path, i)\n",
    "            if os.path.isfile(file_loc) and imghdr.what(file_loc):\n",
    "                img = cv2.imread(file_loc)\n",
    "                if img is None:\n",
    "                    print(f\"Failed to load image: {i}:\", \"Cause: Empty !\")\n",
    "                    failed_img.append(i)\n",
    "                    continue\n",
    "                faceCrop(resized_folder_path, i, img, 1, x, y)\n",
    "            elif os.path.isdir(file_loc):\n",
    "                print(i, \": Is a folder\")\n",
    "            elif i.endswith('.txt'):\n",
    "                None\n",
    "            else:\n",
    "                print(i, \": Is not a supported Image File\")\n",
    "\n",
    "    # clear_output(wait=True)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    print(\"Image Cropping Completed\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    if len(failed_img) != 0:\n",
    "        print(\"\\nThese images failed: \\nReason: Invalid to load: \\n\", failed_img, \"\\nCount:\", len(failed_img))\n",
    "\n",
    "    if len(face_failed) != 0:\n",
    "        print(\"\\nThese images failed: \\nReason: Face not found: \\n\", face_failed, \"\\nCount:\", len(face_failed))\n",
    "\n",
    "main_call(selected_folder, x_crop, y_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of folder along with caption files in a .txt format\n",
    "folder_loc = r''\n",
    "\n",
    "# Maximum count of words to show in \"most used words\"\n",
    "max_word_count = 100\n",
    "\n",
    "# Unique name of character\n",
    "charName = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display most USED words in captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(folder_path, mc=max_word_count):\n",
    "    \n",
    "    mc = int(mc)\n",
    "    \n",
    "    word_counts = Counter()\n",
    "    word_order = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                words = file.read().split(\", \")\n",
    "                for word in words:\n",
    "                    if word not in word_order:\n",
    "                        word_order.append(word)\n",
    "                word_counts.update(words)\n",
    "    \n",
    "    common_words_df = pd.DataFrame(word_counts.most_common(mc), columns=['Word', 'Frequency'])\n",
    "    common_words_dict = dict(word_counts.most_common(mc))\n",
    "    \n",
    "    chronological_list = sorted(common_words_dict.keys(), key=lambda word: common_words_dict[word], reverse=True)\n",
    "    print(\"Common words: \", \"\\n\", common_words_df, \"\\n\", \"Common words Dictionary: \", \"\\n\", common_words_dict, \"\\n\", \"Common words List: \", \"\\n\", chronological_list, \"\\n\")\n",
    "    \n",
    "    return common_words_df, common_words_dict, chronological_list\n",
    "\n",
    "df, word_dict, word_list = get_most_common_words(folder_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the words that you want to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to this list\n",
    "words_to_delete_list = ['photo_\\\\(medium\\\\)', '3d', 'blurry', 'blur',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update .txt files with required words (to be removed/added/updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(folder_path, words_list=words_to_delete_list, charName=charName):\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=\"Processing Caption Files\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read().lower()\n",
    "                words = content.split(\", \")\n",
    "                # print(\"\\n\", words)\n",
    "\n",
    "            # Create a new list without the words to delete\n",
    "            updated_words = [word for word in words if word not in words_list]\n",
    "\n",
    "            # Add UniqueWord to the first of the list if not exist\n",
    "            if words[0] != charName:\n",
    "                # print(words[0].lower())\n",
    "                updated_words.insert(0, charName)\n",
    "\n",
    "            # Join the updated words back into a string\n",
    "            updated_content = ', '.join(updated_words)\n",
    "            # print(\"\\nUpdated:\", updated_content)\n",
    "\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(updated_content)\n",
    "\n",
    "process_files(folder_loc, words_to_delete_list, charName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "torch.cuda.empty_cache()  # Releases all unoccupied cached memory currently held by the caching allocator\n",
    "\n",
    "# CUDA (via Numba)\n",
    "from numba import cuda\n",
    "cuda.select_device(0)  # Selects the GPU of ID 0 (change according to your setup)\n",
    "cuda.close()  # Closes the device, attempting to free all memory allocated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
