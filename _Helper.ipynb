{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "from rembg import remove\n",
    "import imghdr\n",
    "import dlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import io\n",
    "import time\n",
    "from shutil import move\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Init for Image Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- [Enter the Location of the folder w/files inside it] -------------------\n",
    "folder_loc = r\"\"\n",
    "\n",
    "# -------------------- [For Duplicate Image Removal] ------------------------------------------\n",
    "# This is used to remove images that are much smaller and will only artefact if you use them\n",
    "# These values: 700, 700, are suggested, you can change it to any \"SQUARE\" size that you want\n",
    "# Square => x = y\n",
    "x_thres = 700\n",
    "y_thres = 700\n",
    "\n",
    "# -------------------- [For Suitability Check] ------------------------------------------------\n",
    "\n",
    "# Format for below: Abbreviation_full_form(init value)\n",
    "# Min_Confidence(0.9), Min_Size(0.009) (proportional to image size), Min_SharpeningStat(100), Blur_Threshold(100)\n",
    "mc, ms, mss, bt = 0.9, 0.01, 100, 100\n",
    "\n",
    "# The best <x> images will be moved to the folder, if you want all, leave it at 0\n",
    "top_n_img_count = 0\n",
    "\n",
    "# -------------------- [For face crop] --------------------------------------------------------\n",
    "\n",
    "# Face Crop to dimensions x, y; eg(512, 512)\n",
    "# IMP: Keep it square to prevent any code from breaking, thanks\n",
    "x_crop = 512\n",
    "y_crop = 512\n",
    "\n",
    "# -------------------- [Do not touch this] ----------------------------------------------------\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "selected_folder = os.path.join(folder_loc, \"SelectedImages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all images to PNG for easier reading [Heavily Suggested]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_images_to_png(source_folder):\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"The folder {source_folder} does not exist.\")\n",
    "        return\n",
    "    for filename in tqdm(os.listdir(source_folder), desc = \"Processing images to .png\"):\n",
    "        if filename.lower().endswith(('.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp')):\n",
    "            file_path = os.path.join(source_folder, filename)\n",
    "            with Image.open(file_path) as img:\n",
    "                new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                new_file_path = os.path.join(source_folder, new_filename)\n",
    "                try:\n",
    "                    img.save(new_file_path, 'PNG')\n",
    "                    # os.remove(file_path)\n",
    "                except:\n",
    "                    img.convert('RGB').save(new_file_path, \"PNG\", optimize=True)\n",
    "            os.remove(file_path)\n",
    "\n",
    "convert_images_to_png(folder_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Same Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_black_bars(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        cropped_image = image[y:y+h, x:x+w]\n",
    "        return cropped_image\n",
    "    return image\n",
    "\n",
    "def process_images(folder_path, x, y):\n",
    "    duplicate_images_folder = os.path.join(folder_path, \"Duplicate_Images\")\n",
    "    if not os.path.exists(duplicate_images_folder):\n",
    "        os.makedirs(duplicate_images_folder)\n",
    "\n",
    "    small_images_folder = os.path.join(folder_path, \"Small_Images\")\n",
    "    if not os.path.exists(small_images_folder):\n",
    "        os.makedirs(small_images_folder)\n",
    "    \n",
    "    image_hashes = {}\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]\n",
    "    for filename in tqdm(files, desc=\"Processing Images\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        image_no_black_bars = remove_black_bars(image)\n",
    "        \n",
    "        pil_image = Image.fromarray(cv2.cvtColor(image_no_black_bars, cv2.COLOR_BGR2RGB))\n",
    "        h,w = pil_image.size\n",
    "        # print(filename, \"\\n\",h*w, x*y)            \n",
    "        \n",
    "        hash = str(imagehash.average_hash(pil_image))\n",
    "        \n",
    "        # Check for duplicates\n",
    "        if hash in image_hashes:\n",
    "            print(f\"Duplicate found: {filename} is a duplicate of {image_hashes[hash]}\")\n",
    "            os.rename(file_path, os.path.join(duplicate_images_folder, filename))\n",
    "        else:\n",
    "            image_hashes[hash] = filename\n",
    "            if h*w < x*y:\n",
    "                os.rename(file_path, os.path.join(small_images_folder, filename))\n",
    "    \n",
    "    if len([i for i in os.listdir(duplicate_images_folder)]) == 0:\n",
    "        os.rmdir(duplicate_images_folder)\n",
    "\n",
    "process_images(folder_loc, x_thres, y_thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checks Images for Suitability Check [Now with Top \"x\" Images option]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = os.getcwd()\n",
    "\n",
    "modelFile = os.path.join(current_folder, \"opencv_face_detector_uint8.pb\")\n",
    "configFile = os.path.join(current_folder, \"opencv_face_detector.pbtxt\")\n",
    "\n",
    "if os.path.exists(modelFile) != True or os.path.exists(configFile) != True:\n",
    "    print(\"ERROR: KEY FILES FOR RUNNING THIS MODEL NOT FOUND, PLEASE FIND THEM AND INSTALL THEM\")\n",
    "\n",
    "else:\n",
    "    net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    def calculate_image_sharpness(image):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the sharpness of an image using the variance of the Laplacian\n",
    "        \"\"\"\n",
    "        \n",
    "        if image is None or image.size == 0:\n",
    "            return 0\n",
    "        return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "    def is_image_blurry(image, blur_threshold):\n",
    "        \n",
    "        \"\"\"\n",
    "        Check if an image is blurry using the variance of the Laplacian method.\n",
    "        \"\"\"\n",
    "        \n",
    "        variance_of_laplacian = cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "        return variance_of_laplacian < blur_threshold\n",
    "\n",
    "    def detect_faces_and_evaluate(image, min_confidence, min_size, min_sharpness, blur_threshold):\n",
    "        \n",
    "        \"\"\"\n",
    "        Detect faces in an image and evaluate based on size, sharpness, and blurriness.\n",
    "        \"\"\"\n",
    "        \n",
    "        if image is None or image.size == 0:\n",
    "            return []\n",
    "        if is_image_blurry(image, blur_threshold):\n",
    "            return []\n",
    "        (h, w) = image.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        faces_detected = []\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > min_confidence:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "                (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "                startX, startY, endX, endY = max(0, startX), max(0, startY), min(w, endX), min(h, endY)\n",
    "                if startX >= endX or startY >= endY:\n",
    "                    continue\n",
    "                face_region = image[startY:endY, startX:endX]\n",
    "                if face_region.size == 0:\n",
    "                    continue\n",
    "                face_size = (endX - startX) * (endY - startY)\n",
    "                face_sharpness = calculate_image_sharpness(face_region)\n",
    "                if face_size > min_size and face_sharpness > min_sharpness:\n",
    "                    faces_detected.append((confidence, face_size, face_sharpness))\n",
    "        return faces_detected\n",
    "\n",
    "    def remove_black_bars(image):\n",
    "        \n",
    "        \"\"\"\n",
    "        Remove black bars from an image.\n",
    "        \"\"\"\n",
    "\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            cropped_image = image[y:y+h, x:x+w]\n",
    "            return cropped_image\n",
    "        return image\n",
    "\n",
    "def select_best_images(\n",
    "        folder_path:str, \n",
    "        min_confidence:float = 0.9, \n",
    "        min_size:float = 0.009, \n",
    "        min_sharpness:float = 100, \n",
    "        blur_threshold:float = 100,\n",
    "        top_n:int = 0\n",
    "        ):\n",
    "    \n",
    "    selected_images_folder = os.path.join(folder_path, \"SelectedImages\")\n",
    "    if not os.path.exists(selected_images_folder):\n",
    "        os.makedirs(selected_images_folder)\n",
    "    \n",
    "    image_ratings = []  # List to store ratings and file paths\n",
    "    \n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'))]\n",
    "    for filename in tqdm(files, desc=\"Evaluating Images\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(file_path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        \n",
    "        image_no_black_bars = remove_black_bars(image)\n",
    "        \n",
    "        faces_detected = detect_faces_and_evaluate(image_no_black_bars, min_confidence, min_size * image_no_black_bars.size, min_sharpness, blur_threshold)\n",
    "        if faces_detected:\n",
    "            rating = sum([face[0] + face[1] + face[2] for face in faces_detected]) \n",
    "            image_ratings.append((rating, file_path))\n",
    "    \n",
    "    # Sort images based on ratings\n",
    "    if top_n == 0:\n",
    "        top_n = len(files)\n",
    "    top_images = sorted(image_ratings, key=lambda x: x[0], reverse=True)[:top_n]\n",
    "    \n",
    "    for _, top_image_path in top_images:\n",
    "        filename = os.path.basename(top_image_path)\n",
    "        move(top_image_path, os.path.join(selected_images_folder, filename))\n",
    "\n",
    "\n",
    "\n",
    "select_best_images(folder_loc, mc, ms, mss, bt, top_n_img_count)\n",
    "\n",
    "selected_folder = os.path.join(folder_loc, \"SelectedImages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanved Image Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(selected_folder) != True:\n",
    "    selected_folder = folder_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Background of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background_from_images(input_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=\"Processing Images\"):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        with open(input_path, 'rb') as input_file:\n",
    "            input_image = input_file.read()\n",
    "\n",
    "            output_image = remove(input_image)\n",
    "\n",
    "            output_image = Image.open(io.BytesIO(output_image))\n",
    "            output_image.save(output_path)\n",
    "\n",
    "remove_background_from_images(selected_folder, os.path.join(selected_folder, \"No_BG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop Image to Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_img = []\n",
    "face_failed = []\n",
    "\n",
    "def faceCrop(folder_dir, fName, img, imp=1, x=512, y=512):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    _, ext = os.path.splitext(fName)\n",
    "    \n",
    "    fName = fName.split(\".\")[0]\n",
    "    if ext.lower() not in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']:\n",
    "        print(f\"Unsupported image format: {ext}\")\n",
    "        failed_img.append(fName)\n",
    "        return\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # getting orignal dimensions\n",
    "    # print(len(gray), len(gray[0]))\n",
    "    oh, ow = len(gray), len(gray[0])\n",
    "    faces = detector(gray)\n",
    "    # print(fName)\n",
    "    # print(\"original dims:\", ow, oh)\n",
    "    if len(faces) == 0:\n",
    "        face_failed.append(fName)\n",
    "    else:\n",
    "        areas = [face.width() * face.height() for face in faces]\n",
    "        max_area_index = np.argmax(areas)\n",
    "        fx, fy, fw, fh = faces[max_area_index].left(), faces[max_area_index].top(), faces[max_area_index].width(), faces[max_area_index].height()\n",
    "\n",
    "        # Calculate center of the face\n",
    "        cx, cy = fx + fw // 2, fy + fh // 2\n",
    "\n",
    "        # print(\"old: \", fw, fh)\n",
    "        fw, fh = int(fw * imp), int(fh * imp)\n",
    "        # print(\"new: \", fw, fh)\n",
    "        if min(fw, fh) > min(ow, oh):\n",
    "            fw = int(min(ow, oh))\n",
    "            fh = int(min(ow, oh))\n",
    "            # print(\"fixed dims:\", fw, fh)\n",
    "        # fw, fh = min(ow, oh), min(ow, oh)\n",
    "        # print(\"updated: \", fw, fh)\n",
    "\n",
    "        # Determine the size of the square bounding box\n",
    "        max_dim = max(fw, fh)\n",
    "        half_dim = max_dim // 2\n",
    "\n",
    "        # Calculate new top-left corner coordinates\n",
    "        fx = cx - half_dim\n",
    "        fy = cy - half_dim\n",
    "\n",
    "        # Ensure the bounding box stays within image bounds\n",
    "        fx = max(0, fx)\n",
    "        fy = max(0, fy)\n",
    "        # fw = min(img.shape[1] - fx, max_dim)\n",
    "        # fh = min(img.shape[0] - fy, max_dim)\n",
    "        fw = min(img.shape[1] - fx, img.shape[0] - fy)\n",
    "        fh = min(img.shape[1] - fx, img.shape[0] - fy)\n",
    "\n",
    "        # print(\"Remade dims:\", fw, fh)\n",
    "\n",
    "        # Crop the square bounding box\n",
    "        cropped = img[fy:fy+fh, fx:fx+fw]\n",
    "\n",
    "        # Resize the cropped image to the specified dimensions\n",
    "        cropped = cv2.resize(cropped, (x, y))\n",
    "\n",
    "        cv2.imwrite(os.path.join(folder_dir, fName + '.png'), cropped)\n",
    "\n",
    "def main_call(folder_path, x=512, y=512, imp = 1):\n",
    "    resized_folder_path = os.path.join(folder_path, \"Cropped_Images\")\n",
    "    \n",
    "    if not os.path.exists(resized_folder_path):\n",
    "        print(r\"Made /resized folder\")\n",
    "        os.makedirs(resized_folder_path)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(\"Valid Folder Location\")\n",
    "        files = os.listdir(folder_path)\n",
    "        files_img = [i for i in files if not i.endswith('.txt') and not os.path.isdir(os.path.join(folder_path, i))]\n",
    "        print(\"Number of files: \", len(files_img))\n",
    "        itr = 0\n",
    "        for i in tqdm(files_img, desc=\"Processing Files\"):\n",
    "            itr += 1\n",
    "            file_loc = os.path.join(folder_path, i)\n",
    "            if os.path.isfile(file_loc) and imghdr.what(file_loc):\n",
    "                img = cv2.imread(file_loc)\n",
    "                if img is None:\n",
    "                    print(f\"Failed to load image: {i}:\", \"Cause: Empty !\")\n",
    "                    failed_img.append(i)\n",
    "                    continue\n",
    "                else:\n",
    "                    faceCrop(resized_folder_path, i, img, imp, x, y)\n",
    "            elif os.path.isdir(file_loc):\n",
    "                print(i, \": Is a folder\")\n",
    "            elif i.endswith('.txt'):\n",
    "                None\n",
    "            else:\n",
    "                print(i, \": Is not a supported Image File\")\n",
    "\n",
    "    # clear_output(wait=True)\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    print(\"Image Cropping Completed\")\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "    if len(failed_img) != 0:\n",
    "        print(\"\\nThese images failed: \\nReason: Invalid to load: \\n\", failed_img, \"\\nCount:\", len(failed_img))\n",
    "\n",
    "    if len(face_failed) != 0:\n",
    "        print(\"\\nThese images failed: \\nReason: Face not found: \\n\", face_failed, \"\\nCount:\", len(face_failed))\n",
    "\n",
    "# --------------------> If didn't use remBG <--------------------\n",
    "# main_call(selected_folder, x_crop, y_crop, imp = 2)\n",
    "\n",
    "# --------------------> If you do use remBG <--------------------\n",
    "# IMP is a variable that allows the cropping boundary to increase by img_size*imp, suggested: imp = 2\n",
    "main_call(os.path.join(selected_folder, \"No_BG\"), x_crop, y_crop, imp = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [IN WORK] [DO NOT RUN THIS BLOCK] Crop X BEST Images to face, rest zoomed out body crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def more_face_crop(folder_dir, fName, img, x=512, y=512):\n",
    "#     detector = dlib.get_frontal_face_detector()\n",
    "#     _, ext = os.path.splitext(fName)\n",
    "    \n",
    "#     fName = fName.split(\".\")[0]\n",
    "#     if ext.lower() not in ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']:\n",
    "#         print(f\"Unsupported image format: {ext}\")\n",
    "#         failed_img.append(fName)\n",
    "#         return\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = detector(gray)\n",
    "#     print(faces)\n",
    "#     if len(faces) == 0:\n",
    "#         None\n",
    "#         # print(\"--> TO BE ADDED\")\n",
    "#         face_failed.append(fName)\n",
    "#     else:\n",
    "#         # Calculate the maximum bounding box around all detected faces\n",
    "#         fx_min, fy_min, fw_max, fh_max = float('inf'), float('inf'), x, y\n",
    "#         for face in faces:\n",
    "#             fx, fy, fw, fh = face.left(), face.top(), face.width(), face.height()\n",
    "#             print(fx_min, fy_min, fw_max, fh_max)\n",
    "#             print(fx, fy, fw, fh)\n",
    "\n",
    "#             cv2.rectangle(img, (fx, fy), (fx + fw, fy + fh), (255, 0, 0), 2)\n",
    "\n",
    "#             cropped_p = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#             cropped_p.show()\n",
    "\n",
    "#             fx_min = min(fx_min, fx)\n",
    "#             fy_min = min(fy_min, fy)\n",
    "#             fw_max = max(fw_max, fx + fw)\n",
    "#             fh_max = max(fh_max, fy + fh)\n",
    "\n",
    "#             cv2.rectangle(img, (fx, fy), (fx + fw, fy + fh), (0, 255, 0), 2)\n",
    "\n",
    "#             cropped_p = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#             cropped_p.show()\n",
    "\n",
    "#         # Create a square bounding box with top aligned to the topmost area of the head\n",
    "#         side_length = max(fw_max - fx_min, fh_max - fy_min)\n",
    "#         cx = (fx_min + fw_max) // 2\n",
    "#         cy = fy_min + 10  # Add a 10-pixel gap\n",
    "#         fx = cx - side_length // 2\n",
    "#         fy = cy - side_length // 2\n",
    "#         fw = side_length\n",
    "#         fh = side_length\n",
    "\n",
    "#         # Crop the image to the square bounding box\n",
    "#         # cropped = img[fy:fy+fh, fx:fx+fw]\n",
    "#         cv2.rectangle(img, (fx, fy), (fx + fw, fy + fh), (0, 0, 255), 2)\n",
    "\n",
    "#         # Resize the cropped image to the specified dimensions\n",
    "#         # cropped = cv2.resize(cropped, (x, y))\n",
    "#         # cv2.imshow(\"img\", cropped)\n",
    "#         cropped_p = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#         cropped_p.show()\n",
    "                                    \n",
    "\n",
    "#         # cv2.imwrite(os.path.join(folder_dir, fName + '.png'), cropped)\n",
    "    \n",
    "# def main_callX(folder_loc, x, y):\n",
    "#     file_loc = r\"C:\\Users\\parvs\\Downloads\\Alia\\SelectedImages\\SelectedImages\\605804587387098720.png\"\n",
    "#     fName = r\"605804587387098720.png\"\n",
    "#     if os.path.isfile(file_loc) and imghdr.what(file_loc):\n",
    "#             img = cv2.imread(file_loc)\n",
    "#             if img is None:\n",
    "#                 print(f\"Failed to load image:\", \"Cause: Empty !\")\n",
    "#                 # failed_img.append(i)\n",
    "#             more_face_crop(folder_loc, fName, img, x, y)\n",
    "\n",
    "# # Example usage:\n",
    "# main_callX(r\"C:\\Users\\parvs\\Downloads\\Alia\\SelectedImages\\SelectedImages\", 512, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning Helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of folder along with caption files in a .txt format\n",
    "folder_loc = r''\n",
    "\n",
    "# Maximum count of words to show in \"most used words\"\n",
    "max_word_count = 100\n",
    "\n",
    "# Unique name of character\n",
    "charName = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display most USED words in captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words(folder_path, mc=max_word_count):\n",
    "    \n",
    "    mc = int(mc)\n",
    "    \n",
    "    word_counts = Counter()\n",
    "    word_order = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                words = file.read().split(\", \")\n",
    "                for word in words:\n",
    "                    if word not in word_order:\n",
    "                        word_order.append(word)\n",
    "                word_counts.update(words)\n",
    "    \n",
    "    common_words_df = pd.DataFrame(word_counts.most_common(mc), columns=['Word', 'Frequency'])\n",
    "    common_words_dict = dict(word_counts.most_common(mc))\n",
    "    \n",
    "    chronological_list = sorted(common_words_dict.keys(), key=lambda word: common_words_dict[word], reverse=True)\n",
    "    print(\"Common words: \", \"\\n\", common_words_df, \"\\n\", \"Common words Dictionary: \", \"\\n\", common_words_dict, \"\\n\", \"Common words List: \", \"\\n\", chronological_list, \"\\n\")\n",
    "    \n",
    "    return common_words_df, common_words_dict, chronological_list\n",
    "\n",
    "df, word_dict, word_list = get_most_common_words(folder_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the words that you want to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to this list\n",
    "words_to_delete_list = ['photo_\\\\(medium\\\\)', '3d', 'blurry', 'blur']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update .txt files with required words (to be removed/added/updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(folder_path, words_list=words_to_delete_list, charName=charName):\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=\"Processing Caption Files\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                content = file.read().lower()\n",
    "                words = content.split(\", \")\n",
    "                # print(\"\\n\", words)\n",
    "\n",
    "            # Create a new list without the words to delete\n",
    "            updated_words = [word for word in words if word not in words_list]\n",
    "\n",
    "            # Add UniqueWord to the first of the list if not exist\n",
    "            if words[0] != charName.lower() or words[0] != charName:\n",
    "                # print(words[0].lower())\n",
    "                updated_words.insert(0, charName)\n",
    "\n",
    "            # Join the updated words back into a string\n",
    "            updated_content = ', '.join(updated_words)\n",
    "            # print(\"\\nUpdated:\", updated_content)\n",
    "\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(updated_content)\n",
    "\n",
    "process_files(folder_loc, words_to_delete_list, charName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "torch.cuda.empty_cache()  # Releases all unoccupied cached memory currently held by the caching allocator\n",
    "\n",
    "# CUDA (via Numba)\n",
    "from numba import cuda\n",
    "cuda.select_device(0)  # Selects the GPU of ID 0 (change according to your setup)\n",
    "cuda.close()  # Closes the device, attempting to free all memory allocated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
